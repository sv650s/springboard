{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_Project_Tree-Based_Algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sv650s/springboard/blob/master/aic-8_2_8_tree-based-algorithms-mini-project/Mini_Project_Tree-Based_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4RTD8FvdOMZ",
        "colab_type": "text"
      },
      "source": [
        "# Mini Project: Tree-Based Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLOYpXFTdOMc",
        "colab_type": "text"
      },
      "source": [
        "## The \"German Credit\" Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MUodPtYdOMc",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoeHuFaWdOMd",
        "colab_type": "text"
      },
      "source": [
        "This dataset has two classes (these would be considered labels in Machine Learning terms) to describe the worthiness of a personal loan: \"Good\" or \"Bad\". There are predictors related to attributes, such as: checking account status, duration, credit history, purpose of the loan, amount of the loan, savings accounts or bonds, employment duration, installment rate in percentage of disposable income, personal information, other debtors/guarantors, residence duration, property, age, other installment plans, housing, number of existing credits, job information, number of people being liable to provide maintenance for, telephone, and foreign worker status.\n",
        "\n",
        "Many of these predictors are discrete and have been expanded into several 0/1 indicator variables (a.k.a. they have been one-hot-encoded).\n",
        "\n",
        "This dataset has been kindly provided by Professor Dr. Hans Hofmann of the University of Hamburg, and can also be found on the UCI Machine Learning Repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbmdauBqdOMd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBiy2DkLdOMe",
        "colab_type": "text"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5hA-SWkdOMf",
        "colab_type": "text"
      },
      "source": [
        " As we have learned in the previous lectures, Decision Trees as a family of algorithms (irrespective to the particular implementation) are powerful algorithms that can produce models with a predictive accuracy higher than that produced by linear models, such as Linear or Logistic Regression. Primarily, this is due to the fact the DT's can model nonlinear relationships, and also have a number of tuning paramters, that allow for the practicioner to achieve the best possible model. An added bonus is the ability to visualize the trained Decision Tree model, which allows for some insight into how the model has produced the predictions that it has. One caveat here, to keep in mind, is that sometimes, due to the size of the dataset (both in the sense of the number of records, as well as the number of features), the visualization might prove to be very large and complex, increasing the difficulty of interpretation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIAG4FfzdOMf",
        "colab_type": "text"
      },
      "source": [
        "To give you a very good example of how Decision Trees can be visualized and interpreted, we would strongly recommend that, before continuing on with solving the problems in this Mini Project, you take the time to read this fanstastic, detailed and informative blog post: http://explained.ai/decision-tree-viz/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YllrPcJadOMg",
        "colab_type": "text"
      },
      "source": [
        "## Building Your First Decision Tree Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coj2qJ15dOMg",
        "colab_type": "text"
      },
      "source": [
        "So, now it's time to jump straight into the heart of the matter. Your first task, is to build a Decision Tree model, using the aforementioned \"German Credit\" dataset, which contains 1,000 records, and 62 columns (one of them presents the labels, and the other 61 present the potential features for the model.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9nUdbjcdOMh",
        "colab_type": "text"
      },
      "source": [
        "For this task, you will be using the scikit-learn library, which comes already pre-installed with the Anaconda Python distribution. In case you're not using that, you can easily install it using pip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkltQrmvdOMi",
        "colab_type": "text"
      },
      "source": [
        "Before embarking on creating your first model, we would strongly encourage you to read the short tutorial for Decision Trees in scikit-learn (http://scikit-learn.org/stable/modules/tree.html), and then dive a bit deeper into the documentation of the algorithm itself (http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzoQQGGFdOMi",
        "colab_type": "text"
      },
      "source": [
        "Also, since you want to be able to present the results of your model, we suggest you take a look at the tutorial for accuracy metrics for classification models (http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) as well as the more detailed documentation (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
        "\n",
        "Finally, an *amazing* resource that explains the various classification model accuracy metrics, as well as the relationships between them, can be found on Wikipedia: https://en.wikipedia.org/wiki/Confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbqB5blHdOMj",
        "colab_type": "text"
      },
      "source": [
        "(Note: as you've already learned in the Logistic Regression mini project, a standard practice in Machine Learning for achieving the best possible result when training a model is to use hyperparameter tuning, through Grid Search and k-fold Cross Validation. We strongly encourage you to use it here as well, not just because it's standard practice, but also becuase it's not going to be computationally to intensive, due to the size of the dataset that you're working with. Our suggestion here is that you split the data into 70% training, and 30% testing. Then, do the hyperparameter tuning and Cross Validation on the training set, and afterwards to a final test on the testing set.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNPbW9ltdOMj",
        "colab_type": "text"
      },
      "source": [
        "### Now we pass the torch onto you! You can start building your first Decision Tree model! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iqI6nTbdOMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww_whpZCdOMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "649b425f-c195-42b0-b304-c5bc0ce7f2a4"
      },
      "source": [
        "# Your code here! :)\n",
        "df = pd.read_csv('GermanCredit.csv')\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 62 columns):\n",
            "Duration                                  1000 non-null int64\n",
            "Amount                                    1000 non-null int64\n",
            "InstallmentRatePercentage                 1000 non-null int64\n",
            "ResidenceDuration                         1000 non-null int64\n",
            "Age                                       1000 non-null int64\n",
            "NumberExistingCredits                     1000 non-null int64\n",
            "NumberPeopleMaintenance                   1000 non-null int64\n",
            "Telephone                                 1000 non-null int64\n",
            "ForeignWorker                             1000 non-null int64\n",
            "Class                                     1000 non-null object\n",
            "CheckingAccountStatus.lt.0                1000 non-null int64\n",
            "CheckingAccountStatus.0.to.200            1000 non-null int64\n",
            "CheckingAccountStatus.gt.200              1000 non-null int64\n",
            "CheckingAccountStatus.none                1000 non-null int64\n",
            "CreditHistory.NoCredit.AllPaid            1000 non-null int64\n",
            "CreditHistory.ThisBank.AllPaid            1000 non-null int64\n",
            "CreditHistory.PaidDuly                    1000 non-null int64\n",
            "CreditHistory.Delay                       1000 non-null int64\n",
            "CreditHistory.Critical                    1000 non-null int64\n",
            "Purpose.NewCar                            1000 non-null int64\n",
            "Purpose.UsedCar                           1000 non-null int64\n",
            "Purpose.Furniture.Equipment               1000 non-null int64\n",
            "Purpose.Radio.Television                  1000 non-null int64\n",
            "Purpose.DomesticAppliance                 1000 non-null int64\n",
            "Purpose.Repairs                           1000 non-null int64\n",
            "Purpose.Education                         1000 non-null int64\n",
            "Purpose.Vacation                          1000 non-null int64\n",
            "Purpose.Retraining                        1000 non-null int64\n",
            "Purpose.Business                          1000 non-null int64\n",
            "Purpose.Other                             1000 non-null int64\n",
            "SavingsAccountBonds.lt.100                1000 non-null int64\n",
            "SavingsAccountBonds.100.to.500            1000 non-null int64\n",
            "SavingsAccountBonds.500.to.1000           1000 non-null int64\n",
            "SavingsAccountBonds.gt.1000               1000 non-null int64\n",
            "SavingsAccountBonds.Unknown               1000 non-null int64\n",
            "EmploymentDuration.lt.1                   1000 non-null int64\n",
            "EmploymentDuration.1.to.4                 1000 non-null int64\n",
            "EmploymentDuration.4.to.7                 1000 non-null int64\n",
            "EmploymentDuration.gt.7                   1000 non-null int64\n",
            "EmploymentDuration.Unemployed             1000 non-null int64\n",
            "Personal.Male.Divorced.Seperated          1000 non-null int64\n",
            "Personal.Female.NotSingle                 1000 non-null int64\n",
            "Personal.Male.Single                      1000 non-null int64\n",
            "Personal.Male.Married.Widowed             1000 non-null int64\n",
            "Personal.Female.Single                    1000 non-null int64\n",
            "OtherDebtorsGuarantors.None               1000 non-null int64\n",
            "OtherDebtorsGuarantors.CoApplicant        1000 non-null int64\n",
            "OtherDebtorsGuarantors.Guarantor          1000 non-null int64\n",
            "Property.RealEstate                       1000 non-null int64\n",
            "Property.Insurance                        1000 non-null int64\n",
            "Property.CarOther                         1000 non-null int64\n",
            "Property.Unknown                          1000 non-null int64\n",
            "OtherInstallmentPlans.Bank                1000 non-null int64\n",
            "OtherInstallmentPlans.Stores              1000 non-null int64\n",
            "OtherInstallmentPlans.None                1000 non-null int64\n",
            "Housing.Rent                              1000 non-null int64\n",
            "Housing.Own                               1000 non-null int64\n",
            "Housing.ForFree                           1000 non-null int64\n",
            "Job.UnemployedUnskilled                   1000 non-null int64\n",
            "Job.UnskilledResident                     1000 non-null int64\n",
            "Job.SkilledEmployee                       1000 non-null int64\n",
            "Job.Management.SelfEmp.HighlyQualified    1000 non-null int64\n",
            "dtypes: int64(61), object(1)\n",
            "memory usage: 484.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZHg6rRynHAx",
        "colab_type": "text"
      },
      "source": [
        "# Let explore the data a little bit before we jump into impelementation\n",
        "\n",
        "Looks like there is 1000 samples in the file\n",
        "\n",
        "*   Class  is the column we want to use for classification\n",
        "  * This is in string format so we will have to convert this to 0/1\n",
        "*   Data is skewed  towards  Good with 700 samples with this classification and only 300 for Bad\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAy-Nm0RnfHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "8a313ecb-a3fc-467c-96aa-42022ea20284"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Amount</th>\n",
              "      <th>InstallmentRatePercentage</th>\n",
              "      <th>ResidenceDuration</th>\n",
              "      <th>Age</th>\n",
              "      <th>NumberExistingCredits</th>\n",
              "      <th>NumberPeopleMaintenance</th>\n",
              "      <th>Telephone</th>\n",
              "      <th>ForeignWorker</th>\n",
              "      <th>Class</th>\n",
              "      <th>CheckingAccountStatus.lt.0</th>\n",
              "      <th>CheckingAccountStatus.0.to.200</th>\n",
              "      <th>CheckingAccountStatus.gt.200</th>\n",
              "      <th>CheckingAccountStatus.none</th>\n",
              "      <th>CreditHistory.NoCredit.AllPaid</th>\n",
              "      <th>CreditHistory.ThisBank.AllPaid</th>\n",
              "      <th>CreditHistory.PaidDuly</th>\n",
              "      <th>CreditHistory.Delay</th>\n",
              "      <th>CreditHistory.Critical</th>\n",
              "      <th>Purpose.NewCar</th>\n",
              "      <th>Purpose.UsedCar</th>\n",
              "      <th>Purpose.Furniture.Equipment</th>\n",
              "      <th>Purpose.Radio.Television</th>\n",
              "      <th>Purpose.DomesticAppliance</th>\n",
              "      <th>Purpose.Repairs</th>\n",
              "      <th>Purpose.Education</th>\n",
              "      <th>Purpose.Vacation</th>\n",
              "      <th>Purpose.Retraining</th>\n",
              "      <th>Purpose.Business</th>\n",
              "      <th>Purpose.Other</th>\n",
              "      <th>SavingsAccountBonds.lt.100</th>\n",
              "      <th>SavingsAccountBonds.100.to.500</th>\n",
              "      <th>SavingsAccountBonds.500.to.1000</th>\n",
              "      <th>SavingsAccountBonds.gt.1000</th>\n",
              "      <th>SavingsAccountBonds.Unknown</th>\n",
              "      <th>EmploymentDuration.lt.1</th>\n",
              "      <th>EmploymentDuration.1.to.4</th>\n",
              "      <th>EmploymentDuration.4.to.7</th>\n",
              "      <th>EmploymentDuration.gt.7</th>\n",
              "      <th>EmploymentDuration.Unemployed</th>\n",
              "      <th>Personal.Male.Divorced.Seperated</th>\n",
              "      <th>Personal.Female.NotSingle</th>\n",
              "      <th>Personal.Male.Single</th>\n",
              "      <th>Personal.Male.Married.Widowed</th>\n",
              "      <th>Personal.Female.Single</th>\n",
              "      <th>OtherDebtorsGuarantors.None</th>\n",
              "      <th>OtherDebtorsGuarantors.CoApplicant</th>\n",
              "      <th>OtherDebtorsGuarantors.Guarantor</th>\n",
              "      <th>Property.RealEstate</th>\n",
              "      <th>Property.Insurance</th>\n",
              "      <th>Property.CarOther</th>\n",
              "      <th>Property.Unknown</th>\n",
              "      <th>OtherInstallmentPlans.Bank</th>\n",
              "      <th>OtherInstallmentPlans.Stores</th>\n",
              "      <th>OtherInstallmentPlans.None</th>\n",
              "      <th>Housing.Rent</th>\n",
              "      <th>Housing.Own</th>\n",
              "      <th>Housing.ForFree</th>\n",
              "      <th>Job.UnemployedUnskilled</th>\n",
              "      <th>Job.UnskilledResident</th>\n",
              "      <th>Job.SkilledEmployee</th>\n",
              "      <th>Job.Management.SelfEmp.HighlyQualified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bad</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bad</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Duration  ...  Job.Management.SelfEmp.HighlyQualified\n",
              "0         6  ...                                       0\n",
              "1        48  ...                                       0\n",
              "2        12  ...                                       0\n",
              "3        42  ...                                       0\n",
              "4        24  ...                                       0\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNOsZGxi2Vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d252ecf5-bb8a-4a65-b3e3-cbadda9ac79b"
      },
      "source": [
        "df.loc[0:5, 'Class']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Good\n",
              "1     Bad\n",
              "2    Good\n",
              "3    Good\n",
              "4     Bad\n",
              "5    Good\n",
              "Name: Class, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJNh2eA6kmlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class is what we are trying to predict - we are going  to map it to 0/1\n",
        "# 0 - Bad\n",
        "# 1- Good\n",
        "y = df['Class'].map({'Bad': 0, 'Good': 1})\n",
        "\n",
        "# drop this from our features\n",
        "x = df.drop(['Class'], axis='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VlmeQWjlUTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f2790f84-3be6-4318-c755-a3b5a97c8434"
      },
      "source": [
        "y.groupby(y).size()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0    300\n",
              "1    700\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLwvsJQXmgFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "98710463-21a0-4d2a-fdd3-0a8108175c70"
      },
      "source": [
        "# split into train and test set\n",
        "# stratify since we have imbalanced classes - this will shuffly by default\n",
        "# 70% train / 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, \n",
        "                                                    y, \n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=1, \n",
        "                                                    stratify=y)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "700\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAvuJQ7Ou4JI",
        "colab_type": "text"
      },
      "source": [
        "## Let's train the model with default values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5E5qvcYxqOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(y_true, y_predict):\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(y_true, y_predict, labels=[0,1],\n",
        "                                  target_names=['Bad', 'Good']\n",
        "                                  ))\n",
        "  print(\"\\nConfusion Matrix:\")\n",
        "  print(confusion_matrix(y_test, predict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq6tV9R0txwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(random_state=1)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "predict = clf.predict(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1dSoVg0vTRz",
        "colab_type": "text"
      },
      "source": [
        "## Let's look at how we did with  default model\n",
        "\n",
        "Precision:\n",
        "Model is better at accurately classifying Good than Bad\n",
        "* 43%  of the time when model predicts Bad, it is Good\n",
        "* 74% of the time when model predict Good, it is Good\n",
        "\n",
        "Recall\n",
        "\n",
        "Model again is better at identifying Good vs Bad\n",
        "\n",
        "* 80% of all Goods were classified as Good\n",
        "* only 36% of all Bads were classified as Bad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtUYax7ax36H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "11fe227b-2f03-4af5-c066-84f87aa27e3b"
      },
      "source": [
        "evaluate_model(y_test, predict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.43      0.36      0.39        90\n",
            "        Good       0.74      0.80      0.77       210\n",
            "\n",
            "    accuracy                           0.67       300\n",
            "   macro avg       0.59      0.58      0.58       300\n",
            "weighted avg       0.65      0.67      0.66       300\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 32  58]\n",
            " [ 42 168]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yEzCqFswkup",
        "colab_type": "text"
      },
      "source": [
        "## Let's see if we can improve the model by tuning it\n",
        "\n",
        "Documentation recommends the following:\n",
        "* max_depth = 5\n",
        "* min_sample_leaf = 5\n",
        "* class_weight = 'balanced'\n",
        "\n",
        "\n",
        "This provided a slight improvement for the non-dominant class.\n",
        "\n",
        "Precision for Bad stayed the same at 43%\n",
        "Recall for Bad increased from 36% to 59% - meaning that we are getting much better at identifying Bad samples\n",
        "\n",
        "\n",
        "Precision also increased for our dominant class - Good from 74% to 79%.\n",
        "However, overall we are getting worse at identifying Good samples as recall decreased from 79% to 67%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz5seXpGy0Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(max_depth=3, \n",
        "                             min_samples_leaf=5, \n",
        "                             class_weight='balanced',\n",
        "                            random_state=1)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "predict = clf.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzBmlBoGy_MV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "2b93d35f-03bb-4b48-ec9d-03cb9d52856a"
      },
      "source": [
        "evaluate_model(y_test, predict)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.43      0.59      0.50        90\n",
            "        Good       0.79      0.67      0.73       210\n",
            "\n",
            "    accuracy                           0.65       300\n",
            "   macro avg       0.61      0.63      0.61       300\n",
            "weighted avg       0.68      0.65      0.66       300\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 53  37]\n",
            " [ 69 141]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp8MzTTPzuZm",
        "colab_type": "text"
      },
      "source": [
        "## Use GridSearchCV to see if we can find a better model\n",
        "\n",
        "Parameters we will tune here are:\n",
        "* max_depth - we will try 3, 6, 12\n",
        "* min_sample_leaf - 5, 10, 20\n",
        "* min_weight_fraction_left - 0., 0.2, 0.4\n",
        "* max_features - 2, 4, 8\n",
        "\n",
        "We will use 5-fold for cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKB3Uly61DAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b2f28c2d-aa29-4113-9d6a-513d6f295714"
      },
      "source": [
        "grid = {\"max_depth\": [None, 3, 6, 12],\n",
        "       \"min_samples_leaf\": [1, 5, 10, 20],\n",
        "       \"min_weight_fraction_leaf\": [0., 0.2, 0.4],\n",
        "       \"max_features\": [None, 2, 4, 8]}\n",
        "clf = DecisionTreeClassifier(random_state=1)\n",
        "gs = GridSearchCV(clf, cv=5, param_grid=grid, return_train_score=True, verbose=1)\n",
        "gs_fit = gs.fit(X_train, y_train)\n",
        "predict = gs.predict(X_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 960 out of 960 | elapsed:    4.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bmKJ3b3uC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3ac69cb2-d868-4139-9526-379d91207a61"
      },
      "source": [
        "gs.best_params_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': None,\n",
              " 'max_features': None,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_weight_fraction_leaf': 0.2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggntlgQ64SiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44e42701-82d5-49da-a9c6-ce5b603b3857"
      },
      "source": [
        "gs.best_score_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7157142857142857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJFLF5mF4-yH",
        "colab_type": "text"
      },
      "source": [
        "### Analysis for GridSearchCV\n",
        "\n",
        "Slight improvement for precision for Bad samples - 45% to 50%\n",
        "Although we are gettting worse at identifying these samples over all since recall dropped from 50% to 42%\n",
        "\n",
        "We are getting less accurate for identifying Good sampels as well since our precision dropped from 79% to 77%\n",
        "However, we are geting better that overall identifying Good samples as recall increased from 67% to 82%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAhUxxBx4amJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "74186cd7-96d5-4ebc-c66f-7758575ea91a"
      },
      "source": [
        "evaluate_model(y_test, predict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.50      0.42      0.46        90\n",
            "        Good       0.77      0.82      0.79       210\n",
            "\n",
            "    accuracy                           0.70       300\n",
            "   macro avg       0.63      0.62      0.63       300\n",
            "weighted avg       0.69      0.70      0.69       300\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 38  52]\n",
            " [ 38 172]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_yfgO0NdOMp",
        "colab_type": "text"
      },
      "source": [
        "### After you've built the best model you can, now it's time to visualize it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHf9lxmadOMq",
        "colab_type": "text"
      },
      "source": [
        "Rememeber that amazing blog post from a few paragraphs ago, that demonstrated how to visualize and interpret the results of your Decision Tree model. We've seen that this can perform very well, but let's see how it does on the \"German Credit\" dataset that we're working on, due to it being a bit larger than the one used by the blog authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAFRjCGDdOMr",
        "colab_type": "text"
      },
      "source": [
        "First, we're going to need to install their package. If you're using Anaconda, this can be done easily by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmo2uznydOMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "70c5ddae-bb35-484b-fec3-e96d474231fb"
      },
      "source": [
        "! pip install dtreeviz"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dtreeviz in /usr/local/lib/python3.6/dist-packages (0.4)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (3.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.21.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.24.2)\n",
            "Requirement already satisfied: graphviz>=0.9 in /usr/local/lib/python3.6/dist-packages (from dtreeviz) (0.10.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dtreeviz) (0.10.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dtreeviz) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dtreeviz) (0.13.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->dtreeviz) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->dtreeviz) (41.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->dtreeviz) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qbl9ao4dOMt",
        "colab_type": "text"
      },
      "source": [
        "If for any reason this way of installing doesn't work for you straight out of the box, please refer to the more detailed documentation here: https://github.com/parrt/dtreeviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG3lgkqudOMu",
        "colab_type": "text"
      },
      "source": [
        "Now you're ready to visualize your Decision Tree model! Please feel free to use the blog post for guidance and inspiration!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzmA9jkd8Fnh",
        "colab_type": "text"
      },
      "source": [
        "# I'm not sure what to do next. I've tried installed this package on my macbook pro but I can't get it to work. I've tried pinging the writer of this package and followed all the instrauctions but it doesn't seem to work. When I run this on google Colab, it does not show any graph just a blank screen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJRAHjRRdOMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dtreeviz.trees import *\n",
        "\n",
        "viz = dtreeviz(gs.best_estimator_, \n",
        "               X_train, \n",
        "               y_train,\n",
        "               target_name='Class',\n",
        "              feature_names=X_train.columns, \n",
        "               class_names=[\"Bad\", \"Good\"]  # need class_names for classifier\n",
        "              )  \n",
        "viz.view()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd_ND_h__a-u",
        "colab_type": "text"
      },
      "source": [
        "### Since I can't get dtreeviz to work. I'm going to use the default tree viewer from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-9G12aM_BAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a21fba8e-1200-4c9f-b5b1-a7cdf66e1879"
      },
      "source": [
        "from sklearn import tree\n",
        "tree.plot_tree(gs.best_estimator_.fit(X_train, y_train)) \n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(200.88000000000002, 181.2, 'X[12] <= 0.5\\nentropy = 0.42\\nsamples = 700\\nvalue = [210, 490]'),\n",
              " Text(133.92000000000002, 108.72, 'X[0] <= 22.5\\nentropy = 0.485\\nsamples = 431\\nvalue = [178, 253]'),\n",
              " Text(66.96000000000001, 36.23999999999998, 'entropy = 0.429\\nsamples = 250\\nvalue = [78, 172]'),\n",
              " Text(200.88000000000002, 36.23999999999998, 'entropy = 0.494\\nsamples = 181\\nvalue = [100, 81]'),\n",
              " Text(267.84000000000003, 108.72, 'entropy = 0.21\\nsamples = 269\\nvalue = [32, 237]')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8aYRPwf3rqbgWlTm+UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsK9HnEg_y3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "b91effcf-ffd4-431a-f28a-a67dcb003f6c"
      },
      "source": [
        " dot_data = tree.export_graphviz(gs.best_estimator_, out_file=None, \n",
        "                      feature_names=X_train.columns,  \n",
        "                      class_names=['Bad', 'Good'],  \n",
        "                      filled=True, rounded=True,  \n",
        "                      special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f368b894be0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"349pt\" height=\"314pt\"\n viewBox=\"0.00 0.00 349.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 345,-310 345,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#8ec7f0\" stroke=\"#000000\" d=\"M316.5,-306C316.5,-306 95.5,-306 95.5,-306 89.5,-306 83.5,-300 83.5,-294 83.5,-294 83.5,-235 83.5,-235 83.5,-229 89.5,-223 95.5,-223 95.5,-223 316.5,-223 316.5,-223 322.5,-223 328.5,-229 328.5,-235 328.5,-235 328.5,-294 328.5,-294 328.5,-300 322.5,-306 316.5,-306\"/>\n<text text-anchor=\"start\" x=\"91.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">CheckingAccountStatus.none ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"172.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.42</text>\n<text text-anchor=\"start\" x=\"158\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 700</text>\n<text text-anchor=\"start\" x=\"148\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [210, 490]</text>\n<text text-anchor=\"start\" x=\"163\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Good</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#c4e2f7\" stroke=\"#000000\" d=\"M187,-187C187,-187 79,-187 79,-187 73,-187 67,-181 67,-175 67,-175 67,-116 67,-116 67,-110 73,-104 79,-104 79,-104 187,-104 187,-104 193,-104 199,-110 199,-116 199,-116 199,-175 199,-175 199,-181 193,-187 187,-187\"/>\n<text text-anchor=\"start\" x=\"83.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">Duration ≤ 22.5</text>\n<text text-anchor=\"start\" x=\"95\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.485</text>\n<text text-anchor=\"start\" x=\"85\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 431</text>\n<text text-anchor=\"start\" x=\"75\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [178, 253]</text>\n<text text-anchor=\"start\" x=\"90\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Good</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M180.4681,-222.8796C175.109,-214.1434 169.4021,-204.8404 163.8718,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"166.8533,-193.9919 158.6408,-187.2981 160.8865,-197.6522 166.8533,-193.9919\"/>\n<text text-anchor=\"middle\" x=\"152.8161\" y=\"-207.9101\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#54aae9\" stroke=\"#000000\" d=\"M329,-179.5C329,-179.5 229,-179.5 229,-179.5 223,-179.5 217,-173.5 217,-167.5 217,-167.5 217,-123.5 217,-123.5 217,-117.5 223,-111.5 229,-111.5 229,-111.5 329,-111.5 329,-111.5 335,-111.5 341,-117.5 341,-123.5 341,-123.5 341,-167.5 341,-167.5 341,-173.5 335,-179.5 329,-179.5\"/>\n<text text-anchor=\"start\" x=\"245.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.21</text>\n<text text-anchor=\"start\" x=\"231\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 269</text>\n<text text-anchor=\"start\" x=\"225\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [32, 237]</text>\n<text text-anchor=\"start\" x=\"236\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Good</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M231.5319,-222.8796C238.3448,-211.7735 245.7198,-199.7513 252.5794,-188.5691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"255.704,-190.1691 257.9497,-179.8149 249.7372,-186.5087 255.704,-190.1691\"/>\n<text text-anchor=\"middle\" x=\"263.7744\" y=\"-200.4269\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#93c9f1\" stroke=\"#000000\" d=\"M112,-68C112,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 112,0 112,0 118,0 124,-6 124,-12 124,-12 124,-56 124,-56 124,-62 118,-68 112,-68\"/>\n<text text-anchor=\"start\" x=\"24\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.429</text>\n<text text-anchor=\"start\" x=\"14\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 250</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [78, 172]</text>\n<text text-anchor=\"start\" x=\"19\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Good</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5622,-103.9815C100.944,-95.1585 95.0012,-85.8258 89.3497,-76.9506\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.1416,-74.8188 83.8181,-68.2637 86.2371,-78.5787 92.1416,-74.8188\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#fae7d9\" stroke=\"#000000\" d=\"M254,-68C254,-68 154,-68 154,-68 148,-68 142,-62 142,-56 142,-56 142,-12 142,-12 142,-6 148,0 154,0 154,0 254,0 254,0 260,0 266,-6 266,-12 266,-12 266,-56 266,-56 266,-62 260,-68 254,-68\"/>\n<text text-anchor=\"start\" x=\"166\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.494</text>\n<text text-anchor=\"start\" x=\"156\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 181</text>\n<text text-anchor=\"start\" x=\"150\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [100, 81]</text>\n<text text-anchor=\"start\" x=\"166\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Bad</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M159.4378,-103.9815C165.056,-95.1585 170.9988,-85.8258 176.6503,-76.9506\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"179.7629,-78.5787 182.1819,-68.2637 173.8584,-74.8188 179.7629,-78.5787\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdHZu4brdOMy",
        "colab_type": "text"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vTdCqwsdOMz",
        "colab_type": "text"
      },
      "source": [
        "As discussed in the lecture videos, Decision Tree algorithms also have certain undesireable properties. Mainly the have low bias, which is good, but tend to have high variance - which is *not* so good (more about this problem here: https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrsuqcdxdOM0",
        "colab_type": "text"
      },
      "source": [
        "Noticing these problems, the late Professor Leo Breiman, in 2001, developed the Random Forests algorithm, which mitigates these problems, while at the same time providing even higher predictive accuracy than the majority of Decision Tree algorithm implementations. While the curriculum contains two excellent lectures on Random Forests, if you're interested, you can dive into the original paper here: https://link.springer.com/content/pdf/10.1023%2FA%3A1010933404324.pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aOgq2izdOM0",
        "colab_type": "text"
      },
      "source": [
        "In the next part of this assignment, your are going to use the same \"German Credit\" dataset to train, tune, and measure the performance of a Random Forests model. You will also see certain functionalities that this model, even though it's a bit of a \"black box\", provides for some degree of interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVnqAqoXdOM1",
        "colab_type": "text"
      },
      "source": [
        "First, let's build a Random Forests model, using the same best practices that you've used for your Decision Trees model. You can reuse the things you've already imported there, so no need to do any re-imports, new train/test splits, or loading up the data again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21v9xPzIdOM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5FjRuMzdOM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here! :)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJU5ho9jdOM6",
        "colab_type": "text"
      },
      "source": [
        "As mentioned, there are certain ways to \"peek\" into a model created by the Random Forests algorithm. The first, and most popular one, is the Feature Importance calculation functionality. This allows the ML practitioner to see an ordering of the importance of the features that have contributed the most to the predictive accuracy of the model. \n",
        "\n",
        "You can see how to use this in the scikit-learn documentation (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_). Now, if you tried this, you would just get an ordered table of not directly interpretable numeric values. Thus, it's much more useful to show the feature importance in a visual way. You can see an example of how that's done here: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py\n",
        "\n",
        "Now you try! Let's visualize the importance of features from your Random Forests model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_zTiumTdOM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_tv4IfRdOM8",
        "colab_type": "text"
      },
      "source": [
        "A final method for gaining some insight into the inner working of your Random Forests models is a so-called Partial Dependence Plot. The Partial Dependence Plot (PDP or PD plot) shows the marginal effect of a feature on the predicted outcome of a previously fit model. The prediction function is fixed at a few values of the chosen features and averaged over the other features. A partial dependence plot can show if the relationship between the target and a feature is linear, monotonic or more complex. \n",
        "\n",
        "In scikit-learn, PDPs are implemented and available for certain algorithms, but at this point (version 0.20.0) they are not yet implemented for Random Forests. Thankfully, there is an add-on package called **PDPbox** (https://pdpbox.readthedocs.io/en/latest/) which adds this functionality to Random Forests. The package is easy to install through pip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J50arfIdOM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "24d5d6c9-584c-48ef-d5e7-157ab31ed2ac"
      },
      "source": [
        "! pip install pdpbox"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdpbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 470kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pdpbox) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pdpbox) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pdpbox) (1.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from pdpbox) (3.0.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pdpbox) (0.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->pdpbox) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->pdpbox) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->pdpbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->pdpbox) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->pdpbox) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->pdpbox) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->pdpbox) (41.0.1)\n",
            "Building wheels for collected packages: pdpbox\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "Successfully built pdpbox\n",
            "Installing collected packages: pdpbox\n",
            "Successfully installed pdpbox-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI4dw3_xdOM-",
        "colab_type": "text"
      },
      "source": [
        "While we encourage you to read the documentation for the package (and reading package documentation in general is a good habit to develop), the authors of the package have also written an excellent blog post on how to use it, showing examples on different algorithms from scikit-learn (the Random Forests example is towards the end of the blog post): https://briangriner.github.io/Partial_Dependence_Plots_presentation-BrianGriner-PrincetonPublicLibrary-4.14.18-updated-4.22.18.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5lWONbdOM-",
        "colab_type": "text"
      },
      "source": [
        "So, armed with this new knowledge, feel free to pick a few features, and make a couple of Partial Dependence Plots of your own!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3c8z29OdOM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAdxyb4KdONA",
        "colab_type": "text"
      },
      "source": [
        "## (Optional) Advanced Boosting-Based Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33JOeZB1dONB",
        "colab_type": "text"
      },
      "source": [
        "As explained in the video lectures, the next generation of algorithms after Random Forests (that use Bagging, a.k.a. Bootstrap Aggregation) were developed using Boosting, and the first one of these were Gradient Boosted Machines, which are implemented in scikit-learn (http://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFVry4pSdONC",
        "colab_type": "text"
      },
      "source": [
        "Still, in recent years, a number of variations on GBMs have been developed by different research amd industry groups, all of them bringing improvements, both in speed, accuracy and functionality to the original Gradient Boosting algorithms.\n",
        "\n",
        "In no order of preference, these are:\n",
        "1. **XGBoost**: https://xgboost.readthedocs.io/en/latest/\n",
        "2. **CatBoost**: https://tech.yandex.com/catboost/\n",
        "3. **LightGBM**: https://lightgbm.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLWdVcE9dOND",
        "colab_type": "text"
      },
      "source": [
        "If you're using the Anaconda distribution, these are all very easy to install:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8lgCPf8dOND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c66dbdb2-c9cc-43a5-f931-be5e4be77b6f"
      },
      "source": [
        "! conda install -c anaconda py-xgboost"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3yuRZs3dONG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea176a33-a09a-4519-a87b-50aa6fc6d474"
      },
      "source": [
        "! conda install -c conda-forge catboost"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrrjTzawdONK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f6b5f66-832b-4f1f-b256-b4c0d6da5257"
      },
      "source": [
        "! conda install -c conda-forge lightgbm"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_iytdebdONN",
        "colab_type": "text"
      },
      "source": [
        "Your task in this optional section of the mini project is to read the documentation of these three libraries, and apply all of them to the \"German Credit\" dataset, just like you did in the case of Decision Trees and Random Forests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omepDpLUdONN",
        "colab_type": "text"
      },
      "source": [
        "The final deliverable of this section should be a table (can be a pandas DataFrame) which shows the accuracy of all the five algorthms taught in this mini project in one place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqgrIHwRdONN",
        "colab_type": "text"
      },
      "source": [
        "Happy modeling! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsG2oifodONO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}